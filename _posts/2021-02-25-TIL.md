---
title: 20210225TIL
categories:
- TIL
tags: 
- TIL
--- 
# 오늘 한 일    
-------
<br/>

### 알고리즘 해결 전략  
- 어제 끝내기로 했던 분할 정복을 끝내지 못했다. 울타리 문제를 푸는 중인데 임시로 지정해둔 ret 변수에 자꾸 임의의 값이 들어가버려서 
정답이 제대로 나오지 않는 문제가 발생했다. 그래서 함수를 처음 시작할 때 ret을 0으로 초기화 시켜줬는데도 문제가 해결되지 않았다.. 
- 사실 울타리 문제도 처음에는 내가 혼자 짰다가 생각지 못했던 케이스를 발견해서 내 알고리즘으로는 풀 수 없구나를 느끼고 다시 풀이를 보고 짰다. 
아직 알고리즘 부분이 취약한 것 같으니 아침에 조금 더 시간을 할애해야겠다.  

### 파이토치 첫걸음 
- 어제 CNN 실습과 RNN 이론 부분을 하기로 계획을 짰었는데 생각보다 CNN의 실습 부분이 양이 너무 많았다. 기본적인 CNN 구현과 여러가지 모델들을 배웠는데, 
구현해둔 모델은 VGG와 GoogLeNet, ResNet이다.  
- 사실 구현만 했지 정확한 코드 이해는 아직 완벽하지 않아서 내일 RNN을 들어가기 전에 다시 한 번 보려고 한다.  
- 복습도 할 겸 여기에 정리 좀 해둬야겠다. 
> `CNN`은 우리말로는 합성곱 신경망이라고 부른다. 이미지를 인식할 때 주로 사용하는 신경망이라고 한다. 사람이 눈으로 책을 읽을 때 처럼 왼쪽 위에서 오른쪽 아래까지 
일정한 범위를(kernel_size) 필터에 적용시키면서 구하려는 답과 얼마나 일치하는지를 검사하는 방식이다.  
여기서 일정한 범위의 데이터를 하나로 압축시켜 버리면 원래의 입력값과 크기가 달라지게 되는데, 이렇게 자꾸 작아지게 되면 레이어를 쓰는데 한계가 생기기때문에 패딩이라는 것을 한다. 입력값의 테두리 부분에 설정한 데이터를 부여하여 크기를 늘린 상태에서 입력을 주는 것이다.  
반대로 전체적인 특징이 필요한 상황인데 데이터의 크기가 너무 커서 결과를 뽑아내는데 오래걸리는 경우, 특정 영역의 원하는 특징을 뽑아서 사이즈를 줄이는 풀링이라는 방식도 존재한다.  
합성곱의 개념을 이용한 모델 중 책에서 소개한 세가지 모듈을 오늘 구현해 보았다. 각각의 특징만 살짝 소개해보면,  
VGG: 3x3 합성곱과 맥스 풀링, 완전연결 네트워크 이렇게 세 가지 연산으로 모델을 구성하였다. 모델이 여러개가 있는데 모델마다 쓰이는 레이어의 수가 달라진다.  
GoogLeNet: 인셉션 모듈이라는 것을 사용하는 모델이다. 이전 레이어에서 들어온 입력값을 1x1, 3x3, 5x5 합성곱 필터와 3x3 맥스 풀링을 통과시킨다. 같은 입력값에 대해서 범위에 따른 서로 다른 네개의 출력값을 갖는 셈이다. 연산 과정에서 쓰이는 메모리를 줄이기 위해서 합성곱을 하기 전에 1x1 합성곱 필터를 한 번 추가해서 채널의 수를 줄인다. 맥스 풀링은 이후에 합성곱을 해서 채널을 줄인다. 마지막단의 분류 네트워크에서 발생한 손실이 모델의 입력 부분까지 전달이 안 되는 현상을 방지하기 위해 중간중간에 보조 분류기를 둔다.
ResNet: 특정 위치에서 합성곱 연산을 통한 결과와 입력으로 들어온 결과 두 가지를 더해서 다음 레이어에 전달하는 모델이다. 다음 레이어에 전달되는 값이 더하기 연산이라 역전파를 해도 기울기가 1이라 앞으로 전파가 잘 된다. 이러한 점 때문에 GoogLeNet과는 달리 보조 분류기가 필요하지 않다는 장점이 있다. 

- 모델마다 이해가 안되는 부분이 비슷비슷해서 클래스의 작동 원리만 내일 알아보면 될 것 같다. 모델의 전체적인 작동 원리나 핵심 부분은 이해가 잘 가서 다행인것 같다.  


<br/><br/><br/><br/><br/>

# 내일 할 일  
--------
<br/>

### 파이토치 첫걸음  
- 오늘 이해 부족했던 모델들 이해하고 넘어가기 
- RNN 이론 끝내기 
  
### 알고리즘 문제 해결 전략  
- 분할 정복 울타리 문제 끝내기  
- 동적 계획법 끝내기  

