---
title: 20210309TIL 
categories: 
- TIL 
tags: 
- TIL 
---

# 오늘 한 일  
------
<br/> 

### 파이토치 첫걸음  
- 오늘 드디어 책의 마지막 챕터인 GAN을 끝냈다! 먼저 GAN은 Generative Adversarial Network의 약자로, 한글로 풀어쓰면 생성적 적대 신경망이다. 기본적인 원리를 소개하자면 노이즈 벡터를 입력으로 받아 가짜 데이터를 생성하는 `생성자(generator)`부분이 있고, 가짜 데이터와 진짜 데이터를 입력받아 가짜인지 진짜인지 판별하는 `구분자(discriminator)` 부분으로 나뉘었다. 이 모델의 이름이 GAN으로 지어진 이유는 손실 함수의 특성에서 나타난다. 생성자의 입장에서는 실제 데이터와 구분하기 힘든 가짜 데이터를 만들어야한다. 이 기준은 구분자가 가짜 데이터를 실제 데이터라고 판별하게끔 만드는 것이다. 반면에 구분자의 목표는 가짜 데이터와 실제 데이터를 잘 구분하는 것이 이상적인 목표이다. 이렇게 생성자 부분과 구분자 부분이 지향하는 방향이 반대여서 Adversarial이라는 말을 쓰게 되었다. 기본적인 모델은 입력 데이터를 모두 일차원 벡터 형태로 받아 Linear 레이어만 써서 처리해주었고, 그 외에 DCGAN을 추가로 구현해보았는데 이 모델은 데이터를 2차원 형태로 받아 레이어에서 합성곱 연산을 시켜주어 학습을 진행했다.  
- DCGAN 실습을 진행하는 도중 오류가 발생한 부분이 있었는데, 실습에서 사용한 데이터셋은 MNIST 데이터셋 이었다. 그런데 여기에 있는 사진들은 죄다 흑백이고 원래 RGB의 3개의 채널을 가진 사진들과는 달리 이 데이터는 픽셀의 밝기만을 가지고 있는 데이터라 채널이 한개임에도 불구하고, 실습에서 정규화를 시켜줄 때 채널이 3개라 가정하고 정규화를 진행해서 에러가 났었다. 그래서 1개의 채널에 대해서만 정규화를 시켜주게끔 바꾸었더니 코드가 정상적으로 잘 돌아갔다. 그리고 최적화 함수를 backward 시켜줄때 인자로 `retain_variables=True` 라는 값을 넘겨주었는데 이 부분도 오류가 났었다. 찾아보니 저건 예전에 쓰던 표현이고 지금은 `retain_graph=True` 를 대신 써주는 것 같다. 변화도 연산을 해줄때 그래프 내의 모든 내부 버퍼를 날려버리고 연산을 하는데, 그래프의 일부분을 여러번 역전파 하는 경우에 중복적인 연산을 피하기 위해서 그래프를 남겨두는 조건이라고 한다. 

### 알고리즘 
- 저번에 풀지 못했던 트리의 부모 찾기 문제를 해결하였다. 버스를 타고 집에 가던 도중에 갑자기 dfs로 풀면 되겠구나! 하고 떠올라서 바로 풀었더니 시간 초과도 나지 않고 깔끔하게 풀렸다. 꾸역꾸역 그래프 이론과 bfs를 써가며 풀려했던게 너무 쉽게 풀려버리니 약간 허무했다.  
- 추가로 class4에 있는 N과 M 시리즈 문제를 모두 해결했다. 사실 모두 itertools에 있는 함수들을 쓰면 금방 풀리는 문제들이었다. 
- 지금은 RGB 문제를 풀고 있는중인데, 완전 탐색으로는 시간내에 도저히 풀지 못할것 같아서 DP 테이블을 사용해야 할 것 같다. 좀 더 생각해보고 내일 풀어봐야겠다.  



<br/><br/><br/><br/><br/> 

# 내일 할 일 
------
<br/> 

### cs231n 강의 듣고 내용 정리하기 

### 알짜딥러닝 1강 공부하기 